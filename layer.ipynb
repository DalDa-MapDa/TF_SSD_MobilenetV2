{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "# Define the file path and the extraction path\n",
    "file_path = 'ssd_mobilenet_v3_small_coco_2020_01_14.tar.gz'\n",
    "extract_path = 'model'\n",
    "\n",
    "# Extract the tar.gz file\n",
    "with tarfile.open(file_path, 'r:gz') as tar:\n",
    "    tar.extractall(path=extract_path)\n",
    "\n",
    "# List the extracted files\n",
    "extracted_files = os.listdir(extract_path)\n",
    "print(extracted_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_dir_path = os.path.join(extract_path, 'ssdlite_mobiledet_cpu_320x320_coco_2020_05_19')\n",
    "extracted_dir_contents = os.listdir(extracted_dir_path)\n",
    "print(extracted_dir_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_labels_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Example usage with os.path for proper path handling\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m current_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18m__file__\u001b[39m))\n\u001b[1;32m     31\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mssdlite_mobiledet_cpu_320x320_coco_2020_05_19\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.tflite\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m output_labels_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt_output\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def generate_labels_from_tflite(model_path, output_labels_path):\n",
    "    # Load the TFLite model\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get details of the output tensors\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # Extract number of output classes\n",
    "    output_tensor = interpreter.tensor(output_details[0]['index'])()\n",
    "    num_classes = output_tensor.shape[-1]\n",
    "\n",
    "    # Generate basic labels\n",
    "    labels = [f\"Label_{i}\" for i in range(num_classes)]\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_labels_path), exist_ok=True)\n",
    "\n",
    "    # Save labels to a file\n",
    "    with open(output_labels_path, 'w') as f:\n",
    "        for label in labels:\n",
    "            f.write(f\"{label}\\n\")\n",
    "\n",
    "    print(f\"Labels saved to {output_labels_path}\")\n",
    "\n",
    "# Example usage with os.path for proper path handling\n",
    "current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "model_path = os.path.join(current_dir, 'model', 'ssdlite_mobiledet_cpu_320x320_coco_2020_05_19', 'model.tflite')\n",
    "output_labels_path = os.path.join(current_dir, 'txt_output', 'labels.txt')\n",
    "\n",
    "generate_labels_from_tflite(model_path, output_labels_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# # Extracted directory path (adjust as needed)\n",
    "# extracted_dir_path = os.path.join('model/ssd_mobilenet_v2_mnasfpn_shared_box_predictor_320x320_coco_sync_2020_05_18')\n",
    "\n",
    "# Load the frozen inference graph\n",
    "model_path = os.path.join(extracted_dir_path, 'tflite_graph.pb')\n",
    "\n",
    "# Load the model\n",
    "def load_frozen_model(model_file):\n",
    "    with tf.io.gfile.GFile(model_file, \"rb\") as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    return graph_def\n",
    "\n",
    "# Load the frozen model\n",
    "graph_def = load_frozen_model(model_path)\n",
    "\n",
    "# Function to classify layers\n",
    "def classify_layers(graph_def):\n",
    "    input_layers = []\n",
    "    hidden_layers = []\n",
    "    output_layers = []\n",
    "\n",
    "    for node in graph_def.node:\n",
    "        # Identify input layer\n",
    "        if 'input' in node.name.lower() or node.op in ['Placeholder']:\n",
    "            input_layers.append(f\"Layer Name: {node.name}, Layer Type: {node.op}\")\n",
    "        # Identify output layer\n",
    "        elif 'output' in node.name.lower() or node.op in ['Softmax', 'Sigmoid', 'Identity', 'ArgMax', 'BBox', 'Decode']:\n",
    "            output_layers.append(f\"Layer Name: {node.name}, Layer Type: {node.op}\")\n",
    "        # Other layers are considered hidden layers\n",
    "        else:\n",
    "            hidden_layers.append(f\"Layer Name: {node.name}, Layer Type: {node.op}\")\n",
    "\n",
    "    # Further refine input layers (typically only 1 or a few)\n",
    "    meaningful_input_layers = [layer for layer in input_layers if 'input' in layer.lower()]\n",
    "\n",
    "    # Further refine output layers (filter out intermediate outputs)\n",
    "    meaningful_output_layers = [layer for layer in output_layers if 'output' in layer.lower() or 'classes' in layer.lower() or 'bbox' in layer.lower() or 'raw' in layer.lower()]\n",
    "\n",
    "    return meaningful_input_layers, hidden_layers, meaningful_output_layers\n",
    "\n",
    "# Classify the layers\n",
    "input_layers, hidden_layers, output_layers = classify_layers(graph_def)\n",
    "\n",
    "# Print number of each type of layer\n",
    "print(f\"Total number of input layers: {len(input_layers)}\")\n",
    "print(f\"Total number of hidden layers: {len(hidden_layers)}\")\n",
    "print(f\"Total number of output layers: {len(output_layers)}\")\n",
    "\n",
    "# Print input layers\n",
    "print(\"\\nInput Layers:\")\n",
    "for layer in input_layers:\n",
    "    print(layer)\n",
    "\n",
    "# Print hidden layers\n",
    "print(\"\\nHidden Layers:\")\n",
    "for layer in hidden_layers:\n",
    "    print(layer)\n",
    "\n",
    "# Print output layers\n",
    "print(\"\\nOutput Layers:\")\n",
    "for layer in output_layers:\n",
    "    print(layer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
